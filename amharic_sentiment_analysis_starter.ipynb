{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# üá™üáπ Amharic Sentiment Analyzer\n",
        "\n",
        "Welcome to the **Ethiopian Data Science & AI Community** starter project!\n",
        "\n",
        "In this notebook, you'll build a sentiment classifier for **Amharic text** ‚Äî a crucial step toward NLP for local languages in Ethiopia.\n",
        "\n",
        "We'll use:\n",
        "- Synthetic Amharic dataset (for learning)\n",
        "- Pre-trained multilingual BERT (mBERT)\n",
        "- Simple classification with `transformers`\n",
        "\n",
        "üéØ Goal: Classify text as `Positive`, `Negative`, or `Neutral`."
      ],
      "metadata": {
        "colab_type": "text"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "install_deps",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Step 1: Install required libraries\n",
        "!pip install -q transformers torch pandas scikit-learn matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "imports"
      },
      "outputs": [],
      "source": [
        "# Step 2: Import libraries\n",
        "import pandas as pd\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 3: Create Sample Amharic Dataset\n",
        "\n",
        "üí° This is **synthetic data** for learning. In real projects, you'd collect real Amharic comments from social media, news, etc. (with consent)."
      ],
      "metadata": {
        "colab_type": "text"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sample_data"
      },
      "outputs": [],
      "source": [
        "# Sample Amharic sentences with sentiment labels\n",
        "data = [\n",
        "    (\"·â†·åä·ãú ·àÇ·ã∞·âµ ·ä•·äï·ã∞·àö·àª·àª·àç ·â∞·àµ·çã ·ä†·àà·äù\", \"Positive\"),\n",
        "    (\"·ã≠·âÖ·à≠·â≥ ·ã´ ·äê·åà·à≠ ·â†·å£·àù ·åç·àç·åΩ ·ä†·ã≠·ã∞·àà·àù\", \"Negative\"),\n",
        "    (\"·àµ·àù·àÖ·äï ·äï·åà·à®·äù\", \"Neutral\"),\n",
        "    (\"·ãà·ã∞ ·ä†·ã≤·àµ ·ä†·â†·â£ ·àò·àò·àà·àµ ·ä•·ãà·ã≥·àà·àÅ\", \"Positive\"),\n",
        "    (\"·ã≠·àÖ ·å•·à© ·äê·åà·à≠ ·ä†·ã≠·ã∞·àà·àù\", \"Negative\"),\n",
        "    (\"·ä®·çç·â∞·äõ ·ã®·âµ·àù·àÖ·à≠·âµ ·ä†·âÖ·àù ·ä†·àà\", \"Positive\"),\n",
        "    (\"·ä•·à± ·ãà·ã∞ ·â§·â± ·àÑ·ã∞\", \"Neutral\"),\n",
        "    (\"·ã≠·âÖ·à≠·â≥·ç£ ·ã´ ·ä†·àµ·ã∞·äì·âÇ ·ä†·ã≠·ã∞·àà·àù\", \"Negative\"),\n",
        "    (\"·ä•·äï·ã∞·åà·äì ·ã∞·àµ ·â•·àé·äõ·àç\", \"Positive\"),\n",
        "    (\"·ã≠·àÖ ·äê·åà·à≠ ·ä†·àç·â∞·àò·â∏·äö·àù\", \"Negative\")\n",
        "]\n",
        "\n",
        "# Convert to DataFrame\n",
        "df = pd.DataFrame(data, columns=[\"text\", \"label\"])\n",
        "print(\"Sample Data:\")\n",
        "print(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 4: Explore the Data"
      ],
      "metadata": {
        "colab_type": "text"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "explore",
        "outputId": "c3d4e5e1-5a96-4a9d-c9b8-3d6f0d7f0c6f"
      },
      "outputs": [],
      "source": [
        "# Check label distribution\n",
        "df['label'].value_counts().plot(kind='bar', title=\"Sentiment Distribution\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.xticks(rotation=0)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 5: Load mBERT Tokenizer and Model"
      ],
      "metadata": {
        "colab_type": "text"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "model_load"
      },
      "outputs": [],
      "source": [
        "# Use mBERT (multilingual BERT) - supports Amharic!\n",
        "model_name = \"bert-base-multilingual-cased\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=3)\n",
        "\n",
        "# Map labels to numbers\n",
        "label_map = {\"Positive\": 0, \"Negative\": 1, \"Neutral\": 2}\n",
        "reverse_label_map = {0: \"Positive\", 1: \"Negative\", 2: \"Neutral\"}\n",
        "df['label_num'] = df['label'].map(label_map)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 6: Tokenize Text"
      ],
      "metadata": {
        "colab_type": "text"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tokenize"
      },
      "outputs": [],
      "source": [
        "# Tokenize all texts\n",
        "encoded = tokenizer(\n",
        "    df['text'].tolist(),\n",
        "    padding=True,\n",
        "    truncation=True,\n",
        "    max_length=64,\n",
        "    return_tensors=\"pt\"\n",
        ")\n",
        "\n",
        "# Prepare labels\n",
        "labels = torch.tensor(df['label_num'].values)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 7: Train-Test Split"
      ],
      "metadata": {
        "colab_type": "text"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "split"
      },
      "outputs": [],
      "source": [
        "# Split into train and test\n",
        "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
        "\n",
        "# Create dataset\n",
        "dataset = TensorDataset(encoded['input_ids'], encoded['attention_mask'], labels)\n",
        "train_size = int(0.8 * len(dataset))\n",
        "test_size = len(dataset) - train_size\n",
        "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=4)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 8: Train the Model (Simple Training Loop)"
      ],
      "metadata": {
        "colab_type": "text"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "train",
        "outputId": "b1f6d5c8-3f9e-4f3e-9d1c-3b49f8a39d9e"
      },
      "outputs": [],
      "source": [
        "# Simple training (1 epoch for demo)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "model.train()\n",
        "\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5)\n",
        "\n",
        "for epoch in range(1):\n",
        "    total_loss = 0\n",
        "    for batch in train_loader:\n",
        "        input_ids, attention_mask, batch_labels = [b.to(device) for b in batch]\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(input_ids, attention_mask=attention_mask, labels=batch_labels)\n",
        "        loss = outputs.loss\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "    print(f\"Epoch {epoch+1}, Average Loss: {total_loss/len(train_loader):.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 9: Evaluate the Model"
      ],
      "metadata": {
        "colab_type": "text"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "evaluate",
        "outputId": "5c3a28c4-5541-4728-9c16-60e51e7e3205"
      },
      "outputs": [],
      "source": [
        "model.eval()\n",
        "predictions = []\n",
        "true_labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in test_loader:\n",
        "        input_ids, attention_mask, batch_labels = [b.to(device) for b in batch]\n",
        "\n",
        "        outputs = model(input_ids, attention_mask=attention_mask)\n",
        "        preds = torch.argmax(outputs.logits, dim=1).cpu().numpy()\n",
        "        labels = batch_labels.cpu().numpy()\n",
        "\n",
        "        predictions.extend(preds)\n",
        "        true_labels.extend(labels)\n",
        "\n",
        "acc = accuracy_score(true_labels, predictions)\n",
        "print(f\"Test Accuracy: {acc:.4f}\")\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(true_labels, predictions, target_names=reverse_label_map.values()))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 10: Try Your Own Amharic Sentence!"
      ],
      "metadata": {
        "colab_type": "text"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "predict_own",
        "outputId": "3d268e8d-75d9-4923-a680-21963628778c"
      },
      "outputs": [],
      "source": [
        "def predict_sentiment(text):\n",
        "    model.eval()\n",
        "    encoded = tokenizer(\n",
        "        text,\n",
        "        return_tensors=\"pt\",\n",
        "        padding=True,\n",
        "        truncation=True,\n",
        "        max_length=64\n",
        "    ).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**encoded)\n",
        "        pred = torch.argmax(outputs.logits, dim=1).item()\n",
        "\n",
        "    return reverse_label_map[pred]\n",
        "\n",
        "# Try it!\n",
        "sample_text = \"·ã≠·àÑ ·â†·å£·àù ·å•·à© ·äê·ãç!\"\n",
        "print(f\"Text: {sample_text}\")\n",
        "print(f\"Predicted Sentiment: {predict_sentiment(sample_text)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ‚úÖ Next Steps & Challenges\n",
        "\n",
        "üîπ **Add more Amharic data** (collect from social media, forums, etc.)\n",
        "üîπ **Translate labels** into Amharic for broader access\n",
        "üîπ **Fine-tune on larger dataset** for better accuracy\n",
        "üîπ **Build a web app** using Streamlit or Gradio\n",
        "üîπ **Contribute your dataset** to the community repo!\n",
        "\n",
        "üìå Join the [Ethiopian Data Science & AI Community](https://www.linkedin.com/groups/...) to share your results!"
      ],
      "metadata": {
        "colab_type": "text"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0

}
